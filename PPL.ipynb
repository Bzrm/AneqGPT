{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCbkSCFMBeZq"
      },
      "source": [
        "!pip3 install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCgwbbtyj994"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import torch\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "from transformers import AutoModelWithLMHead, AutoTokenizer, pipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNoUkNnLCsTk"
      },
      "source": [
        "assert torch.cuda.is_available(), 'у вас не находится гпу'\r\n",
        "\r\n",
        "device = torch.device('cuda:0')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbag_5F6h7F3"
      },
      "source": [
        "!unzip \"aneqs.zip\" # здесь нужно указать путь к архиву с csv-файлом"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykRMQPYoh9fo"
      },
      "source": [
        "aneqs = pd.read_csv('aneqs.csv', encoding='cp1251')\r\n",
        "aneqs.text = aneqs.text.map(lambda x: x.lower())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3YFEdM1HmMW"
      },
      "source": [
        "data_valid = ''\r\n",
        "data_train = ''\r\n",
        "data_len = len(aneqs)\r\n",
        "for text in aneqs.text:\r\n",
        "  text = text + '\\n'\r\n",
        "  if len(data_train) <= 600000:\r\n",
        "    data_train+= text\r\n",
        "  elif len(data_valid) <= 20000:\r\n",
        "    data_valid +=text\r\n",
        "  else:\r\n",
        "    break\r\n",
        "\r\n",
        "\r\n",
        "with open('test_file.txt', 'w', encoding='utf8') as f2:\r\n",
        "  f2.write(data_valid)\r\n",
        "  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5TD6js3iK3Y"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfW-DiTEiYsE"
      },
      "source": [
        "tokenizer.pad_token = 0\r\n",
        "tokenizer.bos_token = 2\r\n",
        "tokenizer.eos_token = 3"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8Q99NChDmTq"
      },
      "source": [
        "!unzip 'AneqGPT_model.zip' #путь к архиву с моделью"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er_QK-CAViEH"
      },
      "source": [
        "aneq_model=AutoModelWithLMHead.from_pretrained('./gpt3-aneqs').to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhuBcv8t6XHg"
      },
      "source": [
        "with open('test_file.txt', encoding='utf-8') as f:\r\n",
        "  content = f.readlines()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gy-5cEL3Y2f"
      },
      "source": [
        "encodings = tokenizer(content, return_tensors='pt', padding=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02WqPe4SXsyp",
        "outputId": "d6ddc8e0-cd96-478f-dc6b-855fba7efb97"
      },
      "source": [
        "max_length = aneq_model.config.n_positions\r\n",
        "stride = 512\r\n",
        "\r\n",
        "lls = []\r\n",
        "for i in tqdm(range(0, encodings.input_ids.size(1), stride)):\r\n",
        "    begin_loc = max(i + stride - max_length, 0)\r\n",
        "    end_loc = min(i + stride, encodings.input_ids.size(1))\r\n",
        "    trg_len = end_loc - i   \r\n",
        "    input_ids = encodings.input_ids[:,begin_loc:end_loc].to(device)\r\n",
        "    target_ids = input_ids.clone()\r\n",
        "    target_ids[:,:-trg_len] = -100\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        outputs = aneq_model(input_ids, labels=target_ids)\r\n",
        "        log_likelihood = outputs[0] * trg_len\r\n",
        "\r\n",
        "    lls.append(log_likelihood)\r\n",
        "\r\n",
        "ppl = torch.exp(torch.stack(lls).sum() / end_loc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whGAyKD49Mre",
        "outputId": "10c88c3e-8b4b-49f3-bc48-c69f13f27b93"
      },
      "source": [
        "print(ppl)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(32.0701, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
