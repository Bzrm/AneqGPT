{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AneqGPT-generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n409epz6-iB5"
      },
      "source": [
        "!pip3 install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egawnI5Qi8EL"
      },
      "source": [
        "Генерация\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn5he-YJjYJC"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import torch\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "from transformers import AutoModelWithLMHead, AutoTokenizer, pipeline"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2OnC4HxjTIY"
      },
      "source": [
        "assert torch.cuda.is_available(), 'у вас не находится гпу'\r\n",
        "\r\n",
        "device = torch.device('cuda:0')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS0dOT2z_6tS"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cduHQjwbi6fX"
      },
      "source": [
        "!unzip 'AneqGPT_model.zip' #путь к архиву с моделью"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl-RhNGtjRXg"
      },
      "source": [
        "model=AutoModelWithLMHead.from_pretrained('./gpt3-aneqs').to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ9efrYDjmyZ"
      },
      "source": [
        "aneq_gen = pipeline('text-generation',model='./gpt3-aneqs', tokenizer=tokenizer,config={'max_length':800})"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQm_wbcNjruS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "009c2ed5-2572-4873-a7c4-8496244547f8"
      },
      "source": [
        "aneq_gen(\"начало анека\") # генерация. Вводится начало, а модель продолжает"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'начало анекашевой казаться, что она стала чувствовать себя шляпой боярского. -'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}